#!/usr/bin/env node
/// <reference types="node" />
/**
 * Auto-Commit Hook ‚Äî LLM module
 *
 * Responsibilities:
 *  - OpenAI-compatible API client
 *  - Generate commit messages using LLM
 *  - System prompt with gitmoji and Jira formatting
 *
 * Notes:
 *  - Fail-fast: throw exceptions on API errors
 *  - Commit message in English with gitmoji
 */

import type { AutoCommitConfig } from "./auto_commit_core";

// ============================================================================
// Types
// ============================================================================

export type LLMMessage = {
  role: "system" | "user" | "assistant";
  content: string;
};

export type LLMUsage = {
  prompt_tokens: number;
  completion_tokens: number;
  total_tokens: number;
};

export type LLMResponse = {
  id: string;
  choices: Array<{
    message: {
      role: string;
      content: string;
    };
    finish_reason: string;
  }>;
  usage?: LLMUsage;
};

export type CommitMessageInput = {
  gitDiff: string;
  sessionContext: string;
  changedFiles: string[];
  jiraKey: string | null;
};

export type CommitMessageResult = {
  message: string;
  usage: LLMUsage | null;
};

export type CommitSummaryResult = {
  summary: string;
  usage: LLMUsage | null;
};

// ============================================================================
// System prompt
// ============================================================================

const SYSTEM_PROMPT = `Generate a git commit message. Follow this EXACT format:

{emoji} {type}({scope}): {short description max 50 chars}

üé´ [{JIRA_KEY}]({JIRA_BASE_URL}{JIRA_KEY})

## üìù Summary
{2-3 sentences describing what was done and why}

## üìÅ New Files
| File | Description |
|------|-------------|
| \`{filename}\` | {what this file does} |

## ‚úèÔ∏è Modified Files
| File | Description |
|------|-------------|
| \`{filename}\` | {what changed} |

---
ü§ñ Auto-generated by Cursor Agent

GITMOJI MAPPING (use emoji BEFORE type):
- feat ‚Üí ‚ú®
- fix ‚Üí üêõ
- refactor ‚Üí ‚ôªÔ∏è
- chore ‚Üí üîß
- docs ‚Üí üìù
- test ‚Üí ‚úÖ
- style ‚Üí üíÑ
- perf ‚Üí ‚ö°
- ci ‚Üí üë∑
- build ‚Üí üèóÔ∏è
- revert ‚Üí ‚è™

SCOPES: hooks, tests, api, config, ci, models, infra, core, utils

RULES:
1. Gitmoji FIRST in header: ‚ú® feat(scope): subject
2. Jira link CLICKABLE markdown (if provided): [PROJ-123](https://jira.example.com/browse/PROJ-123)
3. List source code files only (skip .dll, publish/, bin/, obj/, node_modules/)
4. Use markdown tables for files
5. English only
6. Be specific about what changed in each file
7. Section emojis: üìù Summary, üìÅ New Files, ‚úèÔ∏è Modified Files
8. Output MUST use real newlines. NEVER output escaped \\n, \\r, or \\t sequences.
9. If no Jira key provided, omit the Jira line entirely.`;

const SMART_COMMIT_SYSTEM_PROMPT = `Generate a single-line summary for a Jira Smart Commit.

RULES:
1. Output ONE LINE only (no line breaks).
2. No markdown, no quotes, no bullet points.
3. Keep it concise (max 120 characters).
4. English only.`;

// ============================================================================
// API client
// ============================================================================

type CallLLMResult = {
  content: string;
  usage: LLMUsage | null;
};

function normalizeLlmContent(raw: string): string {
  return raw
    .replace(/\\r\\n/g, "\n")
    .replace(/\\n/g, "\n")
    .replace(/\\t/g, "\t")
    .trim();
}

function normalizeSmartCommitSummary(raw: string): string {
  return normalizeLlmContent(raw)
    .replace(/\s+/g, " ")
    .trim();
}

/**
 * Call OpenAI-compatible API to generate commit message.
 */
export async function callLLM(config: AutoCommitConfig, messages: LLMMessage[]): Promise<CallLLMResult> {
  const url = `${config.llm.baseUrl}/chat/completions`;

  const body = {
    model: config.llm.model,
    messages,
    max_tokens: 1000,
    temperature: 0.3,
  };

  const response = await fetch(url, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${config.llm.apiKey}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify(body),
  });

  if (!response.ok) {
    const errorText = await response.text().catch(() => "Unknown error");
    throw new Error(`LLM API error: ${response.status} ${response.statusText} - ${errorText}`);
  }

  const data = (await response.json()) as LLMResponse;

  if (!data.choices || data.choices.length === 0) {
    throw new Error("LLM API returned no choices");
  }

  const content = data.choices[0].message?.content;

  if (!content || typeof content !== "string") {
    throw new Error("LLM API returned empty content");
  }

  return {
    content: content.trim(),
    usage: data.usage ?? null,
  };
}

// ============================================================================
// Commit message generation
// ============================================================================

// Patterns to exclude from file list (binaries, build artifacts)
const EXCLUDED_PATTERNS = [
  /\/publish\//,
  /\/bin\//,
  /\/obj\//,
  /\/node_modules\//,
  /\/dist\//,
  /\.dll$/,
  /\.exe$/,
  /\.pdb$/,
  /\.cache$/,
  /\.pyc$/,
  /__pycache__/,
];

function filterFiles(files: string[]): string[] {
  return files.filter((f) => !EXCLUDED_PATTERNS.some((p) => p.test(f)));
}

/**
 * Build user prompt from input data.
 */
function buildUserPrompt(
  input: CommitMessageInput,
  jiraBaseUrl: string,
  mode: "full" | "smart-commit" = "full"
): string {
  let prompt = "";

  // Jira key with base URL for clickable link
  if (input.jiraKey && jiraBaseUrl) {
    prompt += `JIRA KEY: ${input.jiraKey}\n`;
    prompt += `JIRA BASE URL: ${jiraBaseUrl}\n`;
    prompt += `FULL JIRA LINK: [${input.jiraKey}](${jiraBaseUrl}${input.jiraKey})\n\n`;
  } else if (input.jiraKey) {
    prompt += `JIRA KEY: ${input.jiraKey} (no base URL configured)\n\n`;
  }

  const context = input.sessionContext.trim();
  if (!context) {
    throw new Error("Session context is empty");
  }
  prompt += `SESSION CONTEXT:\n${context}\n\n`;

  // Filter out binaries and build artifacts
  const sourceFiles = filterFiles(input.changedFiles);

  prompt += `FILES CHANGED (${sourceFiles.length} source files):\n`;
  prompt += sourceFiles.map((f) => `- ${f}`).join("\n") + "\n\n";

  // Git diff (truncated for token limit)
  prompt += "DIFF:\n```\n" + input.gitDiff.slice(0, 5000) + "\n```\n\n";

  if (mode === "smart-commit") {
    prompt += "Generate a single-line summary for a Jira Smart Commit comment.";
  } else {
    prompt += "Generate commit message following the format.";
    if (input.jiraKey && jiraBaseUrl) {
      prompt += " Use the FULL JIRA LINK provided above.";
    }
  }

  return prompt;
}

/**
 * Generate commit message using LLM.
 */
export async function generateCommitMessage(config: AutoCommitConfig, input: CommitMessageInput): Promise<CommitMessageResult> {
  const messages: LLMMessage[] = [
    { role: "system", content: SYSTEM_PROMPT },
    { role: "user", content: buildUserPrompt(input, config.jiraBaseUrl, "full") },
  ];

  const result = await callLLM(config, messages);
  const normalized = normalizeLlmContent(result.content);

  // Basic validation
  if (normalized.length < 50) {
    throw new Error(`Generated commit message too short: ${normalized.length} chars`);
  }

  // Append token usage to footer
  let message = normalized;
  if (result.usage) {
    const tokenInfo = `\nüìä Tokens: ${result.usage.total_tokens} (prompt: ${result.usage.prompt_tokens}, completion: ${result.usage.completion_tokens})`;
    message = message + tokenInfo;
  }

  return {
    message,
    usage: result.usage,
  };
}

/**
 * Generate a single-line summary for Jira Smart Commit.
 */
export async function generateSmartCommitSummary(
  config: AutoCommitConfig,
  input: CommitMessageInput
): Promise<CommitSummaryResult> {
  const messages: LLMMessage[] = [
    { role: "system", content: SMART_COMMIT_SYSTEM_PROMPT },
    { role: "user", content: buildUserPrompt(input, config.jiraBaseUrl, "smart-commit") },
  ];

  const result = await callLLM(config, messages);
  const summary = normalizeSmartCommitSummary(result.content);

  if (!summary) {
    throw new Error("Generated smart commit summary is empty");
  }

  return {
    summary,
    usage: result.usage,
  };
}
